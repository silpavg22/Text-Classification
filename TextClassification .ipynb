{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5J6p-Dafvgb",
        "outputId": "cd9b3533-fed0-4a1a-84bd-9d2e92bbc549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "drive.mount('/content/drive')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvhQdHe_a6wd",
        "outputId": "c81a9432-ea32-4b99-c978-a949528cf1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6TKipOKYgtQY",
        "outputId": "11780d2a-fbc1-494d-d2b0-683cce427d09"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Freshness                                             Review\n",
              "0     fresh   Manakamana doesn't answer any questions, yet ...\n",
              "1     fresh   Wilfully offensive and powered by a chest-thu...\n",
              "2    rotten   It would be difficult to imagine material mor...\n",
              "3    rotten   Despite the gusto its star brings to the role...\n",
              "4    rotten   If there was a good idea at the core of this ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fbfea97-e4eb-4b7a-8c78-522ca3372516\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Freshness</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>fresh</td>\n",
              "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fresh</td>\n",
              "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rotten</td>\n",
              "      <td>It would be difficult to imagine material mor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>rotten</td>\n",
              "      <td>Despite the gusto its star brings to the role...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>rotten</td>\n",
              "      <td>If there was a good idea at the core of this ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fbfea97-e4eb-4b7a-8c78-522ca3372516')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fbfea97-e4eb-4b7a-8c78-522ca3372516 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fbfea97-e4eb-4b7a-8c78-522ca3372516');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data_set=pd.read_csv(\"/content/drive/MyDrive/Assignment2/rt_reviews.csv\",encoding='latin-1')\n",
        "data_set.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJd3o_oetUkZ",
        "outputId": "dc29f138-c0a2-4771-ea0d-f3a0e06c5fe2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "data_set[\"Freshness\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYDSTPtBtkme",
        "outputId": "87695e98-61fc-45ae-b632-cb1f3d033b39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "data_set[\"Review\"].isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting dataset into training, development and test set"
      ],
      "metadata": {
        "id": "oXK7X8i6euA5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKF7H01lh2Bu",
        "outputId": "0b287795-ef5d-4d9c-d5f3-d456dc46641b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(480000, 2)\n",
            "(336000, 2)\n",
            "(96000, 2)\n",
            "(48000, 2)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "data_set.sort_values(by = 'Review', ascending=True, inplace=True)\n",
        "print(data_set.shape)\n",
        "train_split_index = int(0.7 * len(data_set))\n",
        "dev_split_index = int(0.9 * len(data_set))\n",
        "train_data = data_set[:train_split_index]\n",
        "dev_data = data_set[train_split_index:dev_split_index]\n",
        "test_data = data_set[dev_split_index:]\n",
        "\n",
        "print(train_data.shape)\n",
        "print(dev_data.shape)\n",
        "print(test_data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHRYnmm3BkAc",
        "outputId": "e5489a22-dea5-447e-ecee-6bb864a41ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"that'll\", 'an', 'any', 'weren', 'himself', 'have', 'if', 'to', 'with', 'where', 'hers', 'who', 'about', 'here', 'by', \"couldn't\", 'don', 'myself', 'into', 'shan', 'down', \"isn't\", 'doesn', 'very', 'against', 'themselves', 'and', 'our', 'above', 'was', 'as', 'whom', \"weren't\", 'aren', \"mustn't\", 'you', 'are', 'it', 'were', 'isn', 'some', 'off', 'which', 'those', 'we', 'nor', 'having', 'y', 'such', \"haven't\", 'after', 'most', 'no', 'not', 'm', 'of', 'over', 'own', 'can', 'needn', 'ours', 'his', 'in', 'out', 'only', 'didn', 'up', 'the', \"you're\", 'hasn', 'all', 'should', 'before', 'shouldn', \"wouldn't\", 'for', \"hasn't\", \"hadn't\", 'their', 'has', 'mustn', 'from', 'just', \"didn't\", 'mightn', \"it's\", 'because', 'that', \"you've\", 'll', 'yours', 'at', 'wouldn', 'a', 'is', 'does', 'had', 'what', \"wasn't\", 'itself', 'won', 'these', 'when', \"won't\", 'me', \"shouldn't\", 'am', 'haven', 'through', \"you'll\", 'herself', 'its', 'then', 'now', 'between', 'but', 'or', \"doesn't\", 'while', 'so', 'yourself', 'd', 'under', 'both', 'few', 'further', 'him', 'your', 'each', \"aren't\", \"don't\", 've', 'other', 'o', \"mightn't\", 'i', \"she's\", 'they', 'theirs', 'on', 'once', 'this', 're', 'hadn', 'ma', 'than', 'below', 's', 'my', 'do', 'been', \"needn't\", 'her', 'yourselves', 'them', 'why', 't', \"you'd\", 'he', 'she', 'ourselves', 'ain', 'more', 'until', 'again', 'be', \"should've\", 'did', 'will', 'doing', 'being', 'how', 'same', 'too', 'during', 'couldn', 'there', \"shan't\", 'wasn'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "print(stop_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing data"
      ],
      "metadata": {
        "id": "dlCAnyJye0NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def preprocess_and_create_vocabulary(sentences):\n",
        "  word_dict = {}\n",
        "  final_word_dict={}\n",
        "\n",
        "  for i in range(len(sentences)):\n",
        "    sentences[i] = re.sub(r\"\\W\", \" \", sentences[i]) \n",
        "    sentences[i] = re.sub(r\"\\d\", \" \", sentences[i])\n",
        "    sentences[i] = sentences[i].lower()\n",
        "    for word in sentences[i].split():\n",
        "      word = ''.join(lemmatizer.lemmatize(word))\n",
        "      \n",
        "      if word not in stop_words:\n",
        "        word_dict[word] = word_dict.get(word,0) + 1\n",
        "  for k,v in word_dict.items():\n",
        "    if v > 5:\n",
        "      final_word_dict[k] = v\n",
        "  return final_word_dict\n",
        "\n",
        "train_sentences =  train_data[\"Review\"].tolist()\n",
        "final_word_dict=preprocess_and_create_vocabulary(train_sentences)\n"
      ],
      "metadata": {
        "id": "4BmOjYC3f3dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G12vnvA8lVaH",
        "outputId": "79c964b2-7e5b-4df4-f01c-1d9fbc4e523d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28874"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding word occurence probability"
      ],
      "metadata": {
        "id": "xt2gpUDFe3Oo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_prob_word_occurence(word_dict):\n",
        "  prob_word_dict={}\n",
        "  for word,count in word_dict.items():\n",
        "    prob = count/sum(word_dict.values())\n",
        "    prob_word_dict[word] = prob\n",
        "  return prob_word_dict"
      ],
      "metadata": {
        "id": "LuslrduzQDNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding prior probability"
      ],
      "metadata": {
        "id": "MA9Gnwvwe7TS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def find_prior_probability(word_dict,data):\n",
        "  total_rows = len(data)\n",
        "  target_values = list(data[\"Freshness\"].unique())\n",
        "  target_types_dict={}\n",
        "  prior_prob_dict={}\n",
        "  for target in target_values:\n",
        "    count = (data['Freshness'] == target).sum()\n",
        "    target_types_dict[target] = count\n",
        "    prior_prob_dict[target] = count/total_rows\n",
        "  return target_types_dict,prior_prob_dict\n",
        "\n",
        "target_types_dict,prior_prob_dict = find_prior_probability(final_word_dict,train_data)\n",
        "for k,v in prior_prob_dict.items():\n",
        "  print(f\"Prior Probability of {k} is {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fD46xh6Pjjk8",
        "outputId": "9908e606-78ac-4e01-ff0d-e45a35e9ad03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior Probability of rotten is 0.48604761904761906\n",
            "Prior Probability of fresh is 0.5139523809523809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_prob_word_occurence"
      ],
      "metadata": {
        "id": "Plwke64-qLdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a33c8ba-250d-410f-a2a2-3cd8aafe51ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.calculate_prob_word_occurence(word_dict)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_word_dict = calculate_prob_word_occurence(final_word_dict)\n"
      ],
      "metadata": {
        "id": "EU34X66Cx8l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the Conditional Probability"
      ],
      "metadata": {
        "id": "XV0fa1KEe-zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_cond_prob_word(target_types_dict,data,):\n",
        "  cond_prob_dict={}\n",
        "  for target_type in target_types_dict.keys():\n",
        "    sentences_with_class =  data.loc[data['Freshness'] == target_type, 'Review'].tolist()\n",
        "    final_word_dict = preprocess_and_create_vocabulary(sentences_with_class)\n",
        "    for word,count in final_word_dict.items():\n",
        "      total_word_count = sum(final_word_dict.values())\n",
        "      cond_prob_dict[target_type+\" \"+word] = count/total_word_count\n",
        "  return cond_prob_dict\n",
        "\n",
        "\n",
        "cond_prob_dict=find_cond_prob_word(target_types_dict,train_data)"
      ],
      "metadata": {
        "id": "a97gn3Vn01po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the top 10 most occuring words"
      ],
      "metadata": {
        "id": "xKNKjFGAfCtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_10words(target_types_dict,cond_prob_dict):\n",
        "  print(\"The Top 10 words for each class are:\")\n",
        "\n",
        "  for target in target_types_dict.keys():\n",
        "    sorted_dict = dict(sorted(cond_prob_dict.items(), key=lambda x: x[1], reverse=True))\n",
        "    print(f\"For Class {target} :\" )\n",
        "    top_10_values = {key.split()[1]:cond_prob_dict.get(key) for key in cond_prob_dict if key.startswith(target)}\n",
        "    sorted_result = sorted(top_10_values.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "    print(sorted_result)\n",
        "    \n",
        "get_top_10words(target_types_dict,cond_prob_dict)"
      ],
      "metadata": {
        "id": "9lecm8LtRnal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cda062-7b5b-460f-ae62-08f0d5dc3c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Top 10 words for each class are:\n",
            "For Class rotten :\n",
            "[('movie', 0.006173738050147428), ('film', 0.0058559262284871225), ('like', 0.003762812078604959), ('one', 0.0033366496437470324), ('ha', 0.002722246742642547), ('much', 0.002262131120238822), ('make', 0.0022107020273385686), ('story', 0.0020828782624602686), ('character', 0.0019712821239825343), ('even', 0.0019692848776563104)]\n",
            "For Class fresh :\n",
            "[('film', 0.007735729649613801), ('movie', 0.005249900701386461), ('one', 0.004033071490235146), ('ha', 0.002948600835596518), ('like', 0.0027085198042578105), ('story', 0.0025488683337196965), ('make', 0.0022677271662365425), ('performance', 0.0020631510761521506), ('time', 0.0020426210080799275), ('good', 0.0019078471494410956)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_row = dev_data.sample(n=1)\n",
        "type(dev_row)\n",
        "dev_row"
      ],
      "metadata": {
        "id": "Z3U8uR91jjRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes Algorithm"
      ],
      "metadata": {
        "id": "tmrYeSrOfLZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NaiveBayes(alpha,test_data):\n",
        "  for target_type in target_types_dict.keys():\n",
        "    cond_prob = {key.split()[1]:cond_prob_dict.get(key) for key in cond_prob_dict if key.startswith(target_type)}\n",
        "  \n",
        "  den = 1\n",
        "  predction_prob={}\n",
        "  num = 1\n",
        "  k = 1  #no of features is 1 in this case\n",
        " \n",
        "  for target_type in target_types_dict.keys():\n",
        "    prior_prob_class = prior_prob_dict[target_type]\n",
        "    if alpha is None:\n",
        "      for word in test_data:\n",
        "        if word not in stop_words:\n",
        "          if word in cond_prob.keys():\n",
        "            num = num * cond_prob[word]\n",
        "            den = den * prob_word_dict[word]\n",
        "      final_prob = (num * prior_prob_class)/den\n",
        "    else:\n",
        "      for word in test_data:\n",
        "        if word not in stop_words:\n",
        "          if word in cond_prob.keys():\n",
        "            num = num * cond_prob[word] \n",
        "            den = den * prob_word_dict[word]\n",
        "      final_prob = (num + alpha)/den + alpha * k\n",
        "    predction_prob[target_type] = final_prob\n",
        "\n",
        "  max_class, max_acc = max(predction_prob.items(), key=lambda x: x[1])\n",
        "\n",
        "  return max_class,max_acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "YrLVmtVBjpEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting class labels for 10  rows in test dataset and checking accuracy"
      ],
      "metadata": {
        "id": "JkX8eoQOfPIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "correct_predictions=0\n",
        "labels = dev_data[\"Freshness\"]\n",
        "class_labels = np.array(labels.values[:10])\n",
        "# print(class_labels[:10])\n",
        "for i, row in dev_data.iloc[:10].iterrows():\n",
        "  i=1\n",
        "  class_label, acc =  NaiveBayes(None,row)\n",
        "  if class_label == class_labels[i]:\n",
        "    correct_predictions +=1\n",
        "  i+=1\n",
        "prediction_accuracy = correct_predictions/10\n",
        "\n",
        "\n",
        "print(\"Prediction accuracy for 10 rows in developement dataset  : \",prediction_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "f7KZD5f_tHZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without Laplace Smoothing"
      ],
      "metadata": {
        "id": "zvINzFmQITPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_row = dev_data.sample(n=1)"
      ],
      "metadata": {
        "id": "ew2kVjJoKnvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class_label, prob =NaiveBayes(None,test_row)\n",
        "print(f\"Predicted label of {test_row.iloc[0,1]} is : {class_label} with probability {round(prob,2)}\")"
      ],
      "metadata": {
        "id": "BtWmWT5d6z-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With alpha  = 0.4"
      ],
      "metadata": {
        "id": "wftCwX4RIXd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_label, prob =NaiveBayes(0.4,test_row)\n",
        "print(f\"Predicted label of {test_row.iloc[0,1]} is : {class_label} with probability {round(prob,2)}\")"
      ],
      "metadata": {
        "id": "O_9vTByy9uzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With alpha = 0.45"
      ],
      "metadata": {
        "id": "D6GaTDPTIanJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_label, prob =NaiveBayes(0.45,test_row)\n",
        "print(f\"Predicted label of {test_row.iloc[0,1]} is : {class_label} with probability {round(prob,2)}\")"
      ],
      "metadata": {
        "id": "fki0v-fqBVA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With alpha = 0.55"
      ],
      "metadata": {
        "id": "1ATY13Z8Ir_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_label, prob =NaiveBayes(0.55,test_row)\n",
        "print(f\"Predicted label of {test_row.iloc[0,1]} is : {class_label} with probability {round(prob,2)}\")"
      ],
      "metadata": {
        "id": "8yV1gswTBaq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing Smoothing Results"
      ],
      "metadata": {
        "id": "lKoAHd_8fVfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "courses = [ \"alpha = 0.4\", \"alpha = 0.45\", \"alpha = None\", \"alpha = 0.55\"]\n",
        "values = [0.51,0.56,0.51,0.85]\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "plt.bar(courses, values, color ='orange',width = 0.3)\n",
        "\n",
        "plt.xlabel(\"Smoothing Factor\")\n",
        "plt.ylabel(\"Probabilty\")\n",
        "plt.title(\"Comparison of Smoothing\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gd6Qkr-29YDy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}